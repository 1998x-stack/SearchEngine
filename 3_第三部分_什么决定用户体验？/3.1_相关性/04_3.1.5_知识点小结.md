# 04_3.1.5_知识点小结

"""
Lecture: 3_第三部分_什么决定用户体验？/3.1_相关性
Content: 04_3.1.5_知识点小结
"""

## 知识点小结：相关性模型训练

### 一、简介
相关性模型的训练是搜索引擎优化中的关键步骤，通过训练高精度的相关性模型，可以提升用户体验和业务指标。本小结将详细总结相关性模型的训练方法、评价指标和优化策略。

### 二、训练步骤
相关性模型的训练包括预训练、后预训练、微调和蒸馏四个主要步骤。

#### 1. 预训练（Pre-training）
预训练通过大规模无标注的文本数据进行自监督学习，使模型掌握丰富的语言知识和上下文理解能力。主要任务包括掩码语言模型（MLM）和下一句预测（NSP）。
- **MLM**：随机掩码输入文本中的部分词，让模型预测这些词。
- **NSP**：判断两段文本是否相邻。

#### 2. 后预训练（Post Pre-training）
后预训练通过挖掘搜索日志数据，构建大规模的相关性数据集，并进一步训练模型。利用小模型（如GBDT）将用户行为统计量映射到相关性分数上，用这些分数来训练大模型。

#### 3. 微调（Fine-tuning）
微调在人工标注的数据集上进行，通过数十万、数百万条样本，进一步优化模型在特定任务上的表现。高质量的标注数据至关重要，需要制定详细的标注规则并进行严格的质量控制。

#### 4. 蒸馏（Distillation）
蒸馏通过大模型指导小模型的训练，使小模型也能获得大模型的高性能。蒸馏需要大量数据，通常为数亿对（q, d）二元组，通过大模型的输出作为小模型的训练目标。

### 三、模型评价与优化

#### 1. 评价指标
评价指标包括AUC和正逆序比，用于衡量模型的预测和排序效果。
- **AUC**：衡量模型预测的相关性分数与实际标签的一致性，数值越高，模型越准确。
- **正逆序比**：考察模型对文档排序的准确性，通过比较文档对的正序与逆序数量进行评估。

#### 2. 损失函数
损失函数包括Pointwise、Pairwise和预训练损失函数，用于不同阶段的训练优化。
- **Pointwise 损失函数**：如均方误差（MSE）和交叉熵，用于提升AUC指标。
- **Pairwise 损失函数**：如对比损失和pairwise logistic损失，用于提升正逆序比。
- **预训练损失函数**：如MLM损失和NSP损失，确保预训练成果在后续训练中被保留。

### 四、后预训练阶段的数据构建

#### 1. 数据来源
数据来源于搜索引擎的日志数据，记录了用户的搜索行为，包括查询词（query）、点击的文档（document）、停留时间（dwell time）、点击率（CTR）、交互率等。

#### 2. 数据抽取
从搜索日志中抽取数亿对（q, d）二元组，并计算这些二元组的用户行为统计量（如点击率、交互率等）。这些统计量作为特征向量，结合文档文本作为模型输入。

#### 3. 数据标注
利用用户行为数据进行自动标注，通过用户的点击行为和交互行为，为（q, d）对打上相关性标签。点击次数和交互次数越多，相关性越高。

#### 4. 数据清洗
对抽取的数据进行清洗，去除噪声数据和无关数据，保证数据质量。去除重复的查询词和文档对，过滤掉停留时间过短的点击记录，并对查询词和文档文本进行分词、去停用词、词干提取等预处理。

#### 5. 特征工程
对构建的数据集进行特征工程，提取有用的特征向量。常见的特征包括文本特征（如TF-IDF、词向量）、行为特征（如点击率、交互率、停留时间）和上下文特征（如位置、时间等）。

### 五、总结
相关性模型的训练通过预训练、后预训练、微调和蒸馏四个步骤，结合大规模数据和高质量标注数据，显著提升搜索引擎的相关性判断能力。通过合理的训练和优化策略，可以提升用户体验和业务指标。