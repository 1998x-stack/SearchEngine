# 01_2.1.2_多分类任务

"""
Lecture: 2_第二部分_机器学习基础/2.1_机器学习任务
Content: 01_2.1.2_多分类任务
"""

### 多分类任务的极致详细分析

#### 一、任务概述
多分类任务是机器学习中的另一大类基本任务，其目标是将输入特征向量 $ x $ 分类为多个类别之一。不同于二分类任务中的两个类别（0或1），多分类任务中的标签 $ y $ 的取值范围是 $\{0, 1, \cdots, k-1\}$，其中 $ k $ 是类别数量。多分类任务在实际应用中广泛存在，例如图像识别、文本分类和情感分析等。

#### 二、模型选择
多分类任务中最常用的模型是 Softmax 分类器。Softmax 分类器的输出是一个 k 维概率分布向量，代表输入样本属于每个类别的概率。

##### 1. Softmax 函数定义
Softmax 函数是一种归一化指数函数，其数学表达式为：
$$ \text{softmax}(z)_i = \frac{\exp(z_i)}{\sum_{j=1}^{k} \exp(z_j)} $$
其中，$ z $ 是输入的 k 维向量，$ \exp(z_i) $ 表示输入向量第 $ i $ 个元素的指数函数值。

##### 2. Softmax 分类器
Softmax 分类器的数学表达式为：
$$ \pi = \text{softmax}(z), $$
$$ z = Wx + b $$
其中，$ x $ 是输入特征向量，$ W $ 是权重矩阵，$ b $ 是偏置向量。输出向量 $ \pi $ 的第 $ i $ 个元素表示输入样本属于第 $ i $ 类的概率。

在图像识别任务中，输入特征向量 $ x $ 可以是图像的像素值或通过卷积神经网络提取的特征。输出 $ \pi $ 是一个概率分布向量，其中每个元素表示输入图像属于某一类别的概率。

#### 三、模型训练

##### 1. 标签编码
在多分类任务中，标签通常使用 one-hot 编码进行表示。one-hot 编码将每个标签映射到一个 k 维向量，其中对应类别的元素为1，其余元素为0。例如，假设有 k = 10 个类别，标签 3 的 one-hot 编码为：
$$ 3 \rightarrow [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] $$

##### 2. 损失函数
为了训练 Softmax 分类器，通常使用交叉熵（Cross Entropy, CE）作为损失函数。交叉熵用于衡量两个概率分布之间的差异，定义为：
$$ \text{CE}(y, \pi) = -\sum_{j=1}^{k} y_j \cdot \ln \pi_j $$
其中，$ y $ 是真实标签的 one-hot 编码向量，$ \pi $ 是模型预测的概率分布向量。

##### 3. 参数更新
使用随机梯度下降（SGD）算法最小化交叉熵损失函数，从而更新分类器的参数 $ W $ 和 $ b $。具体步骤如下：
1. 初始化参数 $ W $ 和 $ b $。
2. 对每个样本 $ (x_i, y_i) $，计算预测值 $ \pi_i = \text{softmax}(Wx_i + b) $。
3. 计算损失函数的梯度：
   $$ \frac{\partial \text{CE}}{\partial W} = (y_i - \pi_i) \cdot x_i^\top $$
   $$ \frac{\partial \text{CE}}{\partial b} = y_i - \pi_i $$
4. 更新参数：
   $$ W \leftarrow W + \eta \cdot \frac{\partial \text{CE}}{\partial W} $$
   $$ b \leftarrow b + \eta \cdot \frac{\partial \text{CE}}{\partial b} $$
   其中，$ \eta $ 是学习率。

#### 四、模型评估

##### 1. 评价指标
多分类模型的常用评价指标包括准确率（Accuracy）、宏平均 F1 分数（Macro F1 Score）和微平均 F1 分数（Micro F1 Score）等。

- **准确率**：预测正确的样本数占总样本数的比例。
- **宏平均 F1 分数**：对每个类别计算 F1 分数，然后取平均值。
- **微平均 F1 分数**：先计算总的真阳性、假阳性和假阴性，再计算 F1 分数。

##### 2. 混淆矩阵
混淆矩阵是一种常用的可视化工具，用于分析分类模型的预测结果。矩阵的每一行表示实际类别，每一列表示预测类别，矩阵的对角线元素表示预测正确的样本数。

#### 五、实际应用中的注意事项

##### 1. 数据预处理
在实际应用中，需要对原始数据进行预处理，包括数据清洗、特征选择和特征工程等。例如，在图像识别任务中，需要对图像进行归一化处理，以消除不同图像之间的尺度差异。

##### 2. 特征工程
特征工程是提升模型性能的关键步骤。通过对原始特征进行转换、组合或生成新的特征，可以提高模型的泛化能力。例如，可以使用卷积神经网络提取图像特征，或者使用词嵌入表示文本特征。

##### 3. 模型调优
模型调优包括选择合适的超参数、使用正则化技术和集成方法等。可以通过交叉验证（Cross-Validation）选择最优的超参数，使用L2正则化防止过拟合，并结合多个分类器的结果进行集成学习（Ensemble Learning）以提高模型的稳定性和准确性。

总结而言，多分类任务是机器学习中的重要任务，通过合理选择模型、优化训练过程和进行特征工程，可以构建高效的多分类模型来解决实际问题。